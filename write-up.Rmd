---
title: "write-up"
author: "Eden Deng, Jane Zhang, Shari Tian"
date: "11/6/2021"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Introduction

# Exploratory Data Analysis and Data Engineering Process

# Model

For $i=1,\ldots,n$ observations, denote each observation's group of scores as $\textbf{Y}_i$, where
$$
\textbf{Y}_{i} = \left( \begin{array}{c}
Y_{i,1}\\
Y_{i,2}\\
Y_{i,3}\\
\end{array} \right) 
= \left( \begin{array}{c}
\text{political participation score}\\
\text{political satisfaction score}\\
\text{economic satisfaction score}\\
\end{array} \right)
$$
For each observation, let $\boldsymbol{\theta} = ({\theta}_1, \theta_2, \theta_3)$ denote the mean scores for 1) political participation, 2) political satisfaction, and 3) economic satisfaction. Also, let $\Sigma$ denote the covariance matrix between the observations, where the $(i,j)^{\text{th}}$ component of $\Sigma$ is the covariance between $Y_i$ and~$Y_j$ and component variances lie along the diagonal.

We will assume that the likelihood of the data follows a multivariate normal distribution. We'll also set semi-conjugate priors on $\theta$ and $\Sigma$ to follow multivariate normal and inverse Wishart distributions, respectively. The full model then becomes:

$$\textbf{Y}_i \mid \boldsymbol{\theta}, \Sigma \sim MVN(\boldsymbol{\theta}, \Sigma).$$ 
$$\boldsymbol{\theta} \sim MVN(\boldsymbol{\mu}_0, \Lambda_0)$$
$$ \Sigma \sim \text{inverseWishart}(\nu_o, S_o^{-1}).$$

### Hyperparameter settings

The prior mean on $\boldsymbol{\theta}$ is best set to be a vector of the theoretical average political participation, political satisfaction, and economic satisfaction score. Since each score ranges from 0 to 1 we will let $\boldsymbol{\mu}_0 = (.5,.5,.5)^T$.

Since the true mean cannot be below 0 or above 1, we will use a prior variance that puts little probability outside this range. Thus, the prior variances on $\boldsymbol{\theta}$ can be set as $\Lambda_0 = (.,.,.)^T$ so that the prior probability that $P(\theta_j \neq [0,1]) = 0.05.$ We will also take the prior correlation of 0.5, or rather $\lambda_{1,2} = ./2 = .$.

For prior settings on $\Sigma$, we will take $S_o$ to be equal to $\boldsymbol{\Lambda}$. We will center $\Sigma$ around $S_o$ by setting 
$\nu_0 = p + . = .$. 

### Gibbs Sampler

In order to sample from the posterior distribution $p(\boldsymbol{\theta}, \Sigma \mid y_1, \ldots, y_n)$, we will implement a Gibbs sampler. From semi-conjugacy, we can derive that the full conditional distribution of $\theta$ is a multivariate normal update, and the full conditional distribution of $\Sigma$ is an inverse Wishart update. 

```{r}
library(mvtnorm)
```


```{r}
# set hyper-parameters
mu0 <- c(0.5,0.5, 0.5)
L0 <- matrix(c(),nrow=3)
nu0 <- 
S0 <- L0
```


```{r}
THETA <- SIGMA <- NULL
set.seed(1)
for (s in 1:5000) {
## update theta
Ln <- solve(solve(L0) + n*solve(Sigma))
mun <- Ln %*% (solve(L0) %*% mu0 +
n*solve(Sigma) %*% ybar)
theta <- rmvnorm(1, mun, Ln)
## update Sigma
Sn <- S0 + (t(Y) - c(theta)) %*% t(t(Y)-c(theta))
Sigma <- solve(rwish(nu0 + n, solve(Sn)))
## save results
THETA <- rbind(THETA, theta)
SIGMA <- rbind(SIGMA, c(Sigma))
}
```

We obtain the following samples from the joint posterior distribution.

### Model Diagnostics 

#### Traceplots

#### Estimated Densities

#### Running Average Plots

# Posterior Inference

# Conclusions

